{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bit2a70bc77268b4f81b593ce476bb08a4d",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mark Jay 코드 기반으로 함.\n",
    "Notebook for streaming data from a microphone in realtime\n",
    "\n",
    "audio is captured using pyaudio\n",
    "then converted from binary data to ints using struct\n",
    "then displayed using matplotlib\n",
    "\n",
    "scipy.fftpack computes the FFT\n",
    "\"\"\"\n",
    "\n",
    "import pyaudio\n",
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fftpack import fft\n",
    "import time\n",
    "from tkinter import TclError\n",
    "\n",
    "# to display in separate Tk window\n",
    "%matplotlib tk\n",
    "\n",
    "# constants\n",
    "CHUNK = 2205   # RATE/200    # samples per frame, 프레임 \n",
    "FORMAT = pyaudio.paInt16     # audio format (bytes per sample?)\n",
    "CHANNELS = 1                 # single channel for microphone\n",
    "RATE = 44100                 # samples per second\n",
    "SECOND_PER_FRAME = CHUNK / RATE  # second per frame, 한 프레임당 걸리는 시간  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(2205, 4410)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "\n",
    "t = np.array(np.linspace(0, SECOND_PER_FRAME, CHUNK)) # len(t) = CHUNK\n",
    "frequency = np.array(np.arange(0, 2*RATE, 1/SECOND_PER_FRAME ))  # len(frequencty) = CHUNK\n",
    "\n",
    "len(t), len(frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4cf033f2f34d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# create matplotlib figure and axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0max1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# pyaudio class instance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyaudio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPyAudio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# create matplotlib figure and axes\n",
    "fig, (ax1, ax2) = plt.subplots(4, figsize=(15, 7))\n",
    "\n",
    "# pyaudio class instance\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# stream object to get data from microphone\n",
    "stream = p.open(\n",
    "    format=FORMAT,\n",
    "    channels=CHANNELS,\n",
    "    rate=RATE,\n",
    "    input=True,\n",
    "    output=True,\n",
    "    frames_per_buffer= CHUNK\n",
    ")\n",
    "\n",
    "# create a line object with random data 실시간 plot을 위한 line 함수들 \n",
    "line, = ax1.plot(t, np.random.rand(CHUNK), '-', lw=2)  # CHUNK갯수 만큼의 rand(0~1 사이의 랜덤 숫자 생성) 행렬을 만든다. \n",
    "\n",
    "line_fft, = ax2.plot(frequency, np.random.rand(CHUNK), '-', lw=2)  # 그냥 \n",
    "\n",
    "# format waveform axes\n",
    "ax1.set_ylim(0, 255)\n",
    "ax1.set_xlim(0, SECOND_PER_FRAME)\n",
    "\n",
    "# format spectrum axes\n",
    "\n",
    "ax2.set_xlim(20, RATE)\n",
    "# ax2.set_ylim(0, 200000)       # 새로 추가 \n",
    "\n",
    "while True:\n",
    "    \n",
    "    # binary data\n",
    "    data = stream.read(CHUNK)  \n",
    "    \n",
    "    # convert data to integers, make np array, then offset it by 127\n",
    "    data_int = struct.unpack(str(2 * CHUNK) + 'B', data)\n",
    "    \n",
    "    # create np array and offset by 128\n",
    "    # data_np = np.array(data_int, dtype='b')[::2] + 128 \n",
    "\n",
    "    data_np = np.array(data_int, dtype='b')[::2] + 128 \n",
    "    \n",
    "    line.set_ydata(data_np) # line(ax1)dp y데이터 입력 \n",
    "    \n",
    "    # compute FFT and update line\n",
    "    yf = fft(data_int)\n",
    "    line_fft.set_ydata(np.abs(yf)  / (128 * CHUNK))  # line_fft(ax2)에 y데이터 입력 \n",
    "    # line_fft.set_ydata(np.abs(yf[0:CHUNK])  / 1 )             # line_fft(ax2)에 y데이터 입력 \n",
    "    # update figure canvas\n",
    "    \n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}